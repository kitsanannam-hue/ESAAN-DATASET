
#!/usr/bin/env python3
"""
Data Quality Checker
====================
‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Thai-Jazz ML Dataset
"""

import json
import pandas as pd
from pathlib import Path
from typing import Dict, List, Any
import re


class DataQualityChecker:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    
    def __init__(self, data_dir: str = "output"):
        self.data_dir = Path(data_dir)
        self.issues = []
        self.stats = {}
    
    def check_music_notation(self) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Musical Notation"""
        notation_path = self.data_dir / "music_notation_dataset" / "musical_notation.json"
        
        if not notation_path.exists():
            self.issues.append("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå musical_notation.json")
            return {}
        
        with open(notation_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        df = pd.DataFrame(data)
        
        quality_report = {
            'total_records': len(df),
            'missing_values': df.isnull().sum().to_dict(),
            'duplicate_records': df.duplicated().sum(),
            'type_distribution': df['type'].value_counts().to_dict() if 'type' in df.columns else {},
            'page_coverage': {
                'min_page': int(df['page'].min()) if 'page' in df.columns else 0,
                'max_page': int(df['page'].max()) if 'page' in df.columns else 0,
                'unique_pages': int(df['page'].nunique()) if 'page' in df.columns else 0
            }
        }
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        if quality_report['missing_values'].get('notation', 0) > 0:
            self.issues.append(f"‚ö†Ô∏è  ‡∏û‡∏ö notation ‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ {quality_report['missing_values']['notation']} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        if quality_report['duplicate_records'] > 0:
            self.issues.append(f"‚ö†Ô∏è  ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥ {quality_report['duplicate_records']} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        return quality_report
    
    def check_phin_dataset(self) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Phin Dataset"""
        phin_path = self.data_dir / "phin_dataset" / "phin_dataset_complete.json"
        
        if not phin_path.exists():
            self.issues.append("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå phin_dataset_complete.json")
            return {}
        
        with open(phin_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        quality_report = {
            'tuning_systems': len(data.get('tuning_systems', [])),
            'lai_patterns': len(data.get('lai_patterns', [])),
            'techniques': len(data.get('techniques', [])),
            'artists': len(data.get('artists', []))
        }
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        for key, count in quality_report.items():
            if count == 0:
                self.issues.append(f"‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {key}")
        
        return quality_report
    
    def check_ml_dataset(self) -> Dict[str, Any]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ML Dataset"""
        ml_path = self.data_dir / "ml_dataset" / "complete_ml_dataset.json"
        
        if not ml_path.exists():
            self.issues.append("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå complete_ml_dataset.json")
            return {}
        
        with open(ml_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        quality_report = {
            'thai_features': len(data.get('thai_traditional_features', {})),
            'jazz_features': len(data.get('jazz_modern_features', {})),
            'hybridization_techniques': len(data.get('hybridization_techniques', [])),
            'scale_mappings': len(data.get('thai_jazz_scale_mappings', []))
        }
        
        return quality_report
    
    def clean_duplicates(self):
        """‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥"""
        notation_path = self.data_dir / "music_notation_dataset" / "musical_notation.csv"
        
        if notation_path.exists():
            df = pd.read_csv(notation_path)
            original_count = len(df)
            df_clean = df.drop_duplicates()
            cleaned_count = len(df_clean)
            
            if original_count > cleaned_count:
                df_clean.to_csv(notation_path, index=False)
                df_clean.to_json(
                    self.data_dir / "music_notation_dataset" / "musical_notation.json",
                    orient='records', force_ascii=False, indent=2
                )
                print(f"‚úÖ ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥ {original_count - cleaned_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    
    def validate_thai_terms(self) -> List[str]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"""
        issues = []
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Phin lai patterns
        lai_path = self.data_dir / "phin_dataset" / "phin_lai_patterns.json"
        if lai_path.exists():
            with open(lai_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            for item in data:
                if not item.get('name_thai'):
                    issues.append(f"‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {item.get('name_english', 'unknown')}")
        
        return issues
    
    def generate_report(self) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        print("=" * 70)
        print("‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Thai-Jazz ML Dataset")
        print("=" * 70)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Musical Notation
        print("\nüìù Musical Notation Dataset:")
        notation_quality = self.check_music_notation()
        if notation_quality:
            print(f"  ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {notation_quality['total_records']} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            print(f"  ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {notation_quality['page_coverage']['unique_pages']} ‡∏´‡∏ô‡πâ‡∏≤")
            print(f"  ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥: {notation_quality['duplicate_records']} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Phin Dataset
        print("\nüéµ Phin Dataset:")
        phin_quality = self.check_phin_dataset()
        if phin_quality:
            print(f"  ‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {phin_quality['tuning_systems']}")
            print(f"  ‡∏•‡∏≤‡∏¢‡πÄ‡∏û‡∏•‡∏á (Lai): {phin_quality['lai_patterns']}")
            print(f"  ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ: {phin_quality['techniques']}")
            print(f"  ‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô: {phin_quality['artists']}")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ML Dataset
        print("\nü§ñ ML Dataset:")
        ml_quality = self.check_ml_dataset()
        if ml_quality:
            print(f"  Thai Features: {ml_quality['thai_features']}")
            print(f"  Jazz Features: {ml_quality['jazz_features']}")
            print(f"  Hybridization: {ml_quality['hybridization_techniques']}")
            print(f"  Scale Mappings: {ml_quality['scale_mappings']}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö
        if self.issues:
            print("\n‚ö†Ô∏è  ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö:")
            for issue in self.issues:
                print(f"  {issue}")
        else:
            print("\n‚úÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        thai_issues = self.validate_thai_terms()
        if thai_issues:
            print("\nüìö ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢:")
            for issue in thai_issues:
                print(f"  {issue}")
        
        print("\n" + "=" * 70)
        
        return "Quality check complete"


def main():
    """Run quality check"""
    checker = DataQualityChecker()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
    checker.generate_report()
    
    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    print("\nüßπ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    checker.clean_duplicates()
    
    print("\n‚ú® ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")


if __name__ == "__main__":
    main()
